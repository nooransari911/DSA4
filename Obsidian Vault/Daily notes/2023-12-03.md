# Cassandra Stackoverflow

### [MongoDB vs. Cassandra closed](https://stackoverflow.com/questions/2892729/mongodb-vs-cassandra)

### [Elasticsearch vs Cassandra vs Elasticsearch with Cassandra](https://stackoverflow.com/questions/27054954/elasticsearch-vs-cassandra-vs-elasticsearch-with-cassandra)

### [Large scale data processing Hbase vs Cassandra closed](https://stackoverflow.com/questions/7237271/large-scale-data-processing-hbase-vs-cassandra)

### [When NOT to use Cassandra? closed](https://stackoverflow.com/questions/2634955/when-not-to-use-cassandra)

### [Difference between partition key, composite key and clustering key in Cassandra?](https://stackoverflow.com/questions/24949676/difference-between-partition-key-composite-key-and-clustering-key-in-cassandra)

### [How does column-oriented NoSQL differ from document-oriented?](https://stackoverflow.com/questions/7565012/how-does-column-oriented-nosql-differ-from-document-oriented)

### [Difference between Document-based and Key/Value-based databases?](https://stackoverflow.com/questions/3554169/difference-between-document-based-and-key-value-based-databases)

### [What does "Document-oriented" vs. Key-Value mean when talking about MongoDB vs Cassandra? closed](https://stackoverflow.com/questions/3046001/what-does-document-oriented-vs-key-value-mean-when-talking-about-mongodb-vs-c)




### [Visual Guide to NoSQL Systems](https://blog.nahurst.com/visual-guide-to-nosql-systems)
### [# Why You Should Never Use MongoDB](http://www.sarahmei.com/blog/2013/11/11/why-you-should-never-use-mongodb/)
### [# ScyllaDB Benchmarks](https://www.scylladb.com/product/benchmarks/)






# Programming Reddit

### [# Squeeze the hell out of the system you have](https://www.reddit.com/r/programming/comments/1896sn1/squeeze_the_hell_out_of_the_system_you_have/)


[# Squeeze the hell out of the system you have](https://blog.danslimmon.com/2023/08/11/squeeze-the-hell-out-of-the-system-you-have/)


> I'd add that squeezing performance equips you a lot better to decide how to scale your architecture later on. You build a deep understanding of your data, the kind of queries you need to perform which is crucial information you need. Scaling is something where you have tradeoffs everywhere, and you need to make decisions that are as informed as possible when deciding on a future architecture.  
> Also I'm not shocked they managed to reduce the load by that much. You'd be surprised about the gains you can find just by profiling and spending the time to understand what your code is actually doing.  
> 	Often people are logging waaaay too much. It's embarrassing having to explain to a team why their servers are running hot - processing a ton of string data when they just need to retrieve a bunch of booleans and numbers.
> 	Logs cost money. A time series metric count of a code path is 10,000 times cheaper and a decent series of graphs often paints a better picture.


> From an investment standpoint it makes sense. The longer you can squeeze the better your return on investment.  


> I couldn't agree more. I find that most times I see a system where it is "needs more power" there are usually super easy fixes like fixing some high frequency query which takes 100ms. Or caching some data which was generating a query in the first place.
> Another common mistake is when people just code badly. They will have a while loop going nuts as part of some weird threading thing they were doing in python.  
> People often forget there are zillions of gigs in a machine. Often the most accessed data might easily fit well inside of the RAM. There is the added complexity of denormalizing the data, but this literally can result in 1000-10000x faster results. Keeping the data in a cache inside something like redis might be a sufficient step. But often if I have a web app which is pretty lightweight, it can still be perfectly reasonable to have each one keep the entire cache locally. This sometimes turns out to be less complex as a this module might go from being one worker of many to a single instance able to keep up with the load.  
> I did a text search cache which saved the top 10,000 searches. This turned out to be wild overkill as the top 500 searches covered over 95% of searches. Needless to say the speedup from a full text search engine was enormous. It also was far more memory efficient than having the database do similar caching. And way faster. A text search against the db was taking about 50ms. The internal module cache was under 1ms.  
> Algorithms are a dark art which can result in amazing results. If the app is data in, data out. Then they might not help. But much of what I do involves calculating things. ML is a common answer to many of the problems I face. The horsepower for most ML tends to be enormous. Replacing the ML with tight fast algos can drop the requirements from an nVidia powered beast to math driven algos running on bottom tier $5 per month VM with room to spare.  
> One huge factor with optimizing things is to keep the system on a single server for as long as possible. Most people don't need more than one server other than for redundancy. Single server systems are so much easier to design and maintain; even when everything is tucked away in a container. 
> 	I fully agree. Nothing more satisfying than achieving large speedups by implementing simple caches and reducing redundant calls. It's surprisingly common to not do so - I am contracted to help commission a system that has dozens of deployments. They are struggling with performance issues on 16 core machines with 64gb ram. Their web client pulls 1.7mbit of data constantly, 99.99% of which is redundant uncompressed text. I am sure that same waste extends through the rest of their code.


> Don't agree at all. You should be working on how to scale your system long before you reach the limits of the fattest single box, so that the new architecture is tested and ready. Otherwise you risk becoming a victim of unexpected growth. Good luck telling the boss that the reason that you had to shut signups is because you wanted to see how far you could squeeze the current architecture.
> It's like suggesting the pull out method to save money on condoms. Sure, it _does_ save money, but you also added a lot of extra risk that you didn't have before.



### [# Code is run more than read](https://www.reddit.com/r/programming/comments/187zf1d/code_is_run_more_than_read/)


[# Code is run more than read](https://olano.dev/2023-11-30-code-is-run-more-than-read/)



### [# Serverless Speed: Rust vs. Go, Java, and Python in AWS Lambda Functions](https://www.reddit.com/r/programming/comments/1853igm/serverless_speed_rust_vs_go_java_and_python_in/)


[# Serverless Speed: Rust vs. Go, Java, and Python in AWS Lambda Functions](https://blog.scanner.dev/serverless-speed-rust-vs-go-java-python-in-aws-lambda-functions/)